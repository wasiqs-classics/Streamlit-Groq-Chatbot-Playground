import streamlit as st
from groq import Groq

# GROQ API Client
client = Groq(api_key=st.secrets.get("GROQ_API_KEY"))

# Store the model in the session state. Like these values will be stored in the session state and will be available throughout the session. (Even if the page is refreshed.)

if "llm" not in st.session_state:
    st.session_state["llm"] = ""

# Do the same for the messages. This will store the chat messages in the session state.
# NOTE: Session state is basically a dictionary that stores the values in the session. It is a way to store the values in the session and access them throughout the session.

if "messages" not in st.session_state:
    st.session_state["messages"] = [] # initializes an empty list.

print("Session State:", st.session_state)

# Header and divider
st.header("Chatbot Playground", divider="violet") # we can also disable anchor by setting anchor=False
st.title(":violet[Welcome to Chat Playground App]", anchor=False) # title adds a title to the app, this is not like HTML title
st.subheader("Powered by Groq", anchor=False) # subheader adds a subheader to the app. Comes with similar text properties

# Sidebar
st.sidebar.title("Configurations") # sidebar.title adds a title to the sidebar

# Adding components to the sidebar

# Model Selection
# function to reset the messages every time the model is changed

def reset_chat():
    st.session_state.messages = []
    st.toast(f"Chat has been reset for {st.session_state.llm}", icon="ðŸ¤–") # toast adds a toast message to the app. The first argument is the message that we want to display in the toast, the second argument is the icon that we want to display in the toast. The icon can be any of the following: "info", "warning", "error", "success".

st.session_state.llm = st.sidebar.selectbox("Select Model: ", ["llama3-8b-8192","mixtral-8x7b-32768", "gemma2-9b-it"], index=0, on_change=reset_chat) #in this line of code we are creating a selectbox in the sidebar. The first argument is the label of the selectbox, the second argument is the options that we want to display in the selectbox, and the third argument is the default index of the selectbox. Every time the user changes the value of the selectbox, the value will be stored in the session state. On_change is a callback function that will be called every time the value of the selectbox is changed. In this case, we are calling the reset_chat function every time the value of the selectbox is changed.

# Parameters
temp = st.sidebar.slider("Temperature", min_value=0.0, max_value=2.0, value=1.0, step=0.1) # slider adds a slider to the sidebar. The first argument is the label of the slider, the second argument is the minimum value of the slider, the third argument is the maximum value of the slider, the fourth argument is the default value of the slider, and the fifth argument is the step value of the slider. Every time the user changes the value of the slider, the value will be stored in the session state.

max_tokens = st.sidebar.slider("Max Tokens", min_value=0, max_value=8192, value=1024, step=128) # similar functionality but for max_tokens

stream = st.sidebar.toggle("Stream", value=True) # toggle adds a toggle button to the sidebar. The first argument is the label of the toggle button and the second argument is the default value of the toggle button. Every time the user changes the value of the toggle button, the value will be stored in the session state. Also, stream generates means that the response generated by the chatbot will be streamed to the app which is useful for long running taks and displays the output word by word.

json_mode = st.sidebar.toggle("JSON Mode", value=False, help="You must also ask the model to return the JSON")

# Advance Parameters
with st.sidebar.expander("Advanced Parameters"): # expander adds an expander to the sidebar. The first argument is the label of the expander.
    top_p = st.slider("Top P", min_value=0.0, max_value=1.0, value=0.9, step=0.1, help="It is not recommended to alter both the temperature and top-p") # slider adds a slider to the expander. The first argument is the label of the slider, the second argument is the minimum value of the slider, the third argument is the maximum value of the slider, the fourth argument is the default value of the slider, and the fifth argument is the step value of the slider. Every time the user changes the value of the slider, the value will be stored in the session state.
    stop_seq = st.text_input("Stop Sequence", value="", help="The model will stop generating tokens when it encounters this sequence") # text_input adds a text input to the expander. The first argument is the label of the text input and the second argument is the default value of the text input. Every time the user changes the value of the text input, the value will be stored in the session state.


# Showing the Chat Messages
for message in st.session_state.messages:
    # {"role" : "user", "content" : "Hello World"}
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Showing input for user prompt
if prompt := st.chat_input(): # here we are checking if the user has entered any input in the chat input. If the user has entered any input, then the value of the input will be stored in the prompt variable.
    # add the message to the message list
    st.session_state.messages.append({"role" : "user", "content" : prompt}) # we are appending the user message to the messages list in the session state.

    # Also showing the new user message
    with st.chat_message("user"):
        st.write(prompt)

    # Let's make an API call and get the response
    with st.chat_message("assistant"):
        # empty container for response
        response_text = st.empty()

        # Make the API call to Groq
        completion = client.chat.completions.create(
            model=st.session_state.llm or "llama3-8b-8192",
            messages=st.session_state.messages,
            stream=stream,
            temperature=temp,
            max_tokens=max_tokens,
            response_format={"type" : "json_format"} if json_mode else {"type" : "text"},
            stop=stop_seq,
            top_p=top_p
        )

        # Constructor and display the response
        full_response = ""

        if stream:
            for chunk in completion:
                full_response += chunk.choices[0].delta.content or ""
                response_text.write(full_response)
        else:
            with st.spinner("Generating Response..."):
                completion.choices[0].message.content
        

        # Add assistant message to the message list
        st.session_state.messages.append({"role" : "assistant", "content" : full_response})